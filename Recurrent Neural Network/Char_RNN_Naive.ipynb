{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LEMD4f9dG3U"
   },
   "source": [
    "# Character Recurrent Neural Network\n",
    "- 셰익스피어 문체를 모방하는 순환신경망 실습 코드입니다.\n",
    "- Embedding 레이어 및 RNN 모델로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgYi5hIIkjOg"
   },
   "source": [
    "## 데이터를 먼저 준비해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13495,
     "status": "ok",
     "timestamp": 1559553888332,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "ODxhI-YBeYKz",
    "outputId": "92de6e7c-9200-41f5-bcba-27b70117970a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!rm -r data\n",
    "import os \n",
    "\n",
    "try:\n",
    "  os.mkdir(\"./data\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0FyjLatdG3V"
   },
   "source": [
    "## 1. Settings\n",
    "### 1) 필요한 라이브러리들을 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVeUr2FjdG3X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18418,
     "status": "ok",
     "timestamp": 1559553893279,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "guzyAtUZPWj3",
    "outputId": "bde65b41-883b-4c94-adbc-d43e9a535102"
   },
   "outputs": [],
   "source": [
    "#!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwWbv_-KdG3a"
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62S5HbY2dG3d"
   },
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVeZybezdG3e"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "# chunk에 대한 설명은 아래 함수정의하면서 하겠습니다.\n",
    "chunk_len = 200\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eKGWH4BdG3h"
   },
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18406,
     "status": "ok",
     "timestamp": 1559553893284,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "2Cg5-Wp0dG3i",
    "outputId": "3184b0dc-bdd5-4f6e-b975-852c6f591572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "# import 했던 string에서 출력가능한 문자들을 다 불러옵니다. \n",
    "all_characters = string.printable\n",
    "\n",
    "# 출력가능한 문자들의 개수를 저장해놓습니다.\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxeLPVWsdG3m"
   },
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18399,
     "status": "ok",
     "timestamp": 1559553893285,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "5LEkE0bxdG3n",
    "outputId": "1e0f0d9d-5e3f-4e2b-cdff-8109675bd492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "# 앞서 다운받은 텍스트 파일을 열어줍니다.\n",
    "\n",
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmTf-IBOdG3r"
   },
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18389,
     "status": "ok",
     "timestamp": 1559553893285,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "bXDt_MmzdG3s",
    "outputId": "25a24ecd-18ef-4343-ee37-29ba09909e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rone:\n",
      "Welcome, destruction, death, and massacre!\n",
      "I see, as in a map, the end of all.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Accursed and unquiet wrangling days,\n",
      "How many of you have mine eyes beheld!\n",
      "My husband lost his li\n"
     ]
    }
   ],
   "source": [
    "# 이 함수는 텍스트 파일의 일부분을 랜덤하게 불러오는 코드입니다.\n",
    "def random_chunk():\n",
    "    # (시작지점 < 텍스트파일 전체길이 - 불러오는 텍스트의 길이)가 되도록 시작점과 끝점을 정합니다.\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsSgzWIRdG3v"
   },
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18382,
     "status": "ok",
     "timestamp": 1559553893286,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "fhY5WxwsdG3v",
    "outputId": "912cc446-a4ef-42ee-a865-130c18144fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 받았을때 이를 인덱스의 배열로 바꿔주는 함수입니다.\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Boc9LQimdG3y"
   },
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDoMmRY2dG3z"
   },
   "outputs": [],
   "source": [
    "# 랜덤한 텍스트 chunk를 불러와서 이를 입력과 목표값을 바꿔주는 함수입니다.\n",
    "# 예를 들어 pytorch라는 문자열이 들어오면 입력은 pytorc / 목표값은 ytorch 가 됩니다.\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsHsRxlodG31"
   },
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94ku2mreuAVn"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 임베딩 함수에 대한 설명은 책과 공식 도큐먼트를 참고하시길 바랍니다.\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teNVxi0cPgi5"
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size=n_characters, \n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size, \n",
    "            output_size=n_characters, \n",
    "            num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18891,
     "status": "ok",
     "timestamp": 1559553893810,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "rOVPmyxodG37",
    "outputId": "b3f31d2f-27f2-4a27-cd58-acec0b8f682e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 \n",
    "\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfpAh13edG3_"
   },
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wRW02JXdG3_"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoiLqf3_dG4C"
   },
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVTQky8vdG4D"
   },
   "outputs": [],
   "source": [
    "# 임의의 문자(start_str)로 시작하는 길이 200짜리 모방 글을 생성하는 코드입니다.\n",
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "\n",
    "        # 여기서 max값을 사용하지 않고 multinomial을 사용하는 이유는 만약 max 값만 쓰는 경우에\n",
    "        # 생성되는 텍스트가 다 the the the the the 이런식으로 나오기 때문입니다.\n",
    "        # multinomial 함수를 통해 높은 값을 가지는 문자들중에 램덤하게 다음 글자를 뽑아내는 방식으로 자연스러운 텍스트를 생성해냅니다.\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNaIweaudG4G"
   },
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 293566,
     "status": "ok",
     "timestamp": 1559554168504,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "6CnV3_andG4H",
    "outputId": "e981b5be-625b-45ba-963a-94a8c71f6c97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.6075], grad_fn=<DivBackward0>) \n",
      "\n",
      ".'AHuH{A_wN1Bfb25A<2>;r8b`CK3]ULL6aA\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2846], grad_fn=<DivBackward0>) \n",
      "\n",
      "be that soeet\n",
      "old shall do mar,\n",
      "Bud all.\n",
      "\n",
      "TPITRO:\n",
      "As ham,\n",
      "Whe lath od ars blere the hfel dat op hit be ar the thoun urlath\n",
      "\n",
      "Bave onke thes dant lup thak,\n",
      "Nn the hibllft thiin\n",
      "Thy ant setes to loud; thi\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2880], grad_fn=<DivBackward0>) \n",
      "\n",
      "bend thelint soure.\n",
      "\n",
      "PIOMAOR:\n",
      "I rows feren and he blast matey, ortien thelen! I llave thour to frove good, be sith it meacks heark-:\n",
      "There thes the sought\n",
      "And wispeetide withal to heats on oars; anden:\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2641], grad_fn=<DivBackward0>) \n",
      "\n",
      "by for with cereling, you hast ind'd that ol then is think and hiis darce, the pitil,\n",
      "I go erentle, thot at sil, it a card, the ginge all brown I as now prathry\n",
      "Wandensel nath, you now I dead hore'd po\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9750], grad_fn=<DivBackward0>) \n",
      "\n",
      "bes in and tay but and your hepbee, me! my meapnive and be pear hith lords mars were wasser:\n",
      "The gopeble your in are deait: have is it that gromey.\n",
      "\n",
      "CALINIUS:\n",
      "I he time the warting and fimith,\n",
      "Now quta\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.5995], grad_fn=<DivBackward0>) \n",
      "\n",
      "best shall me you stard; a\n",
      "rast,\n",
      "Thas a shall prires, the thee castiss dome eyand condiek, thou more came, 'Our theed pintlesse.\n",
      "Rome bet that my frietting thy radies and is a to thou louns of thou he'\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8015], grad_fn=<DivBackward0>) \n",
      "\n",
      "be woull pis;\n",
      "Condek?\n",
      "\n",
      "CORIOPARET:\n",
      "Bander 'tis uther when wohes whis ritalences, and say wanne the proises, loatiir lenvy's stear time all with will our spole\n",
      "Dust of picoue remand tansllanciond,\n",
      "Bence\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8468], grad_fn=<DivBackward0>) \n",
      "\n",
      "being, you lood you sent demeo, I man in that you in to by love for my take Ruth my aghter;\n",
      "Sine-ster,\n",
      "Shat ky faisster.\n",
      "\n",
      "HEMRIOLLO:\n",
      "Shat the jaich cancture thee and thou day, So it off a shome.\n",
      "\n",
      "LOMK:\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7620], grad_fn=<DivBackward0>) \n",
      "\n",
      "bends that my is enean, sir, beld and mane in head inser.\n",
      "\n",
      "FORLORK:\n",
      "Bwill coman as not my with ell;\n",
      "Rilfue wound in you, the his insurness to must all thy madihe the so that spervate in to in thy s sta\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9485], grad_fn=<DivBackward0>) \n",
      "\n",
      "bers this stalie,\n",
      "And you the giss.\n",
      "\n",
      "ASI Ruch there him?- no metience theye of Meace Ware?\n",
      "\n",
      "MERCUG:\n",
      "Nedings it her this the pleds to sir.\n",
      "\n",
      "MARINIO:\n",
      "And this you to thing.\n",
      "\n",
      "TRING RICHARD IIING:\n",
      "Hast,\n",
      "Wh\n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    # 랜덤한 텍스트 덩어리를 샘플링하고 이를 인덱스 텐서로 변환합니다. \n",
    "    inp,label = random_training_set()\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\",\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV7mBpxtjJsy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6.4.4.1 Char_RNN_Naive.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
